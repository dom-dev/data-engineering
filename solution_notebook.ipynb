{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection succesful\n",
      "---START SHRINKING WHITEHOUSE FILE---\n",
      "---FINISH---\n",
      "--- 10.4070000648 seconds ---\n",
      "\n",
      "---START SORTING AND REMOVING DUPLICATES---\n",
      "---FINISH---\n",
      "--- 11.7969999313 seconds ---\n",
      "\n",
      "---START DELETING DUPLICATES---\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from lxml import etree as lxmletree\n",
    "import time, re, pandas\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib2, imdb, csv, os.path\n",
    "\n",
    "\n",
    "##################################################################\n",
    "# UNICODE READER        \n",
    "##################################################################\n",
    "class UnicodeDictReader:\n",
    "    \"\"\"\n",
    "    A CSV reader which will iterate over lines in the CSV file \"variable filename\",\n",
    "    which is encoded in the given encoding.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, f, dialect=csv.excel, encoding=\"latin-1\", **kwds):\n",
    "        self.encoding = encoding\n",
    "        self.reader = csv.DictReader(f, dialect=dialect, **kwds)\n",
    "\n",
    "    def next(self):\n",
    "        row = self.reader.next()\n",
    "        return {k: unicode(v, \"latin-1\") for k, v in row.iteritems()}\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        if exc_type is not None:\n",
    "            print exc_type, exc_value, traceback\n",
    "            # return False # uncomment to pass exception through\n",
    "        return self\n",
    "    \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "##################################################################\n",
    "# MOVIE OBJECTS\n",
    "##################################################################\n",
    "class Movie:\n",
    "    name=\"\"\n",
    "    year=0\n",
    "    rating=\"\"\n",
    "    movie_id=\"\"\n",
    "    directors=[]\n",
    "    writers=[]\n",
    "    cast=[]\n",
    "    \n",
    "    def __init__(self, _name, _year, _rating, _id):\n",
    "        self.name=_name\n",
    "        self.year=_year\n",
    "        self.rating=_rating\n",
    "        self.movie_id=_id\n",
    "\n",
    "##################################################################\n",
    "# HELPER FUNCTIONS\n",
    "##################################################################\n",
    "\"\"\"\n",
    "This Function sorts the attributes Namelast Namefirst according to Namelast descendend.\n",
    "After sorting, it removes all duplicates names.\n",
    "\"\"\"\n",
    "def sortAndCleanCSV(f_in): \n",
    "    print('---START SORTING AND REMOVING DUPLICATES---')\n",
    "    start_time = time.time()\n",
    "    with open (f_in,'r')as datafile:\n",
    "        data = pandas.read_csv(datafile, sep=',')\n",
    "    datafile.close()\n",
    "    #data = pandas.read_csv(f_in, sep=',', iterator=True, chunksize=10000, engine='python') #in case of bigger files\n",
    "    data = data.sort_values(['NAMELAST','NAMEFIRST'],ascending=True)\n",
    "    #data = data.drop_duplicates(subset='NAMELAST', keep='first') #unfortunately, this function deletes non duplicates\n",
    "    data.to_csv(f_in,index=False,mode='wb')\n",
    "    \n",
    "    print (\"---FINISH---\")   \n",
    "    print(\"--- %s seconds ---\\n\" % (time.time() - start_time))\n",
    "\n",
    "\"\"\"\n",
    "This Function deletes all dublicates in Namelast Namefirst \n",
    "\"\"\"\n",
    "\n",
    "def deleteDuplicates(f_in):\n",
    "    f_out = 'temp.csv'\n",
    "    inFile = open(f_in,'r')\n",
    "    outFile = open(f_out,'w')\n",
    "    \n",
    "    print('---START DELETING DUPLICATES---')\n",
    "    start_time = time.time()\n",
    "    listLines = []\n",
    "    listLines_compare = []\n",
    "    \n",
    "    count=0\n",
    "    for row in inFile:\n",
    "        listLines.append(row)\n",
    "         \n",
    "        if(len(listLines)>1000):    \n",
    "            for line in listLines:\n",
    "                if line in listLines_compare:\n",
    "                    continue\n",
    "                else:\n",
    "                    outFile.write(line)\n",
    "                    listLines_compare.append(line)\n",
    "            listLines = []\n",
    "            listLines_compare = []\n",
    "    \n",
    "    for line in listLines:\n",
    "        if line in listLines_compare:\n",
    "            count=count+1\n",
    "            continue\n",
    "        else:\n",
    "            outFile.write(line)\n",
    "            listLines_compare.append(line)\n",
    "        \n",
    "    outFile.close()\n",
    "    inFile.close()\n",
    "    os.remove(f_in)\n",
    "    os.rename(f_out,f_in)\n",
    "    \n",
    "    print('Removed %d duplicates'%count)\n",
    "    print('---FINISH DELETING DUPLICATES---')\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))    \n",
    "    \n",
    "\"\"\"\n",
    "This function is able to change the given charset and put the first letter in capital\n",
    "and the rest in lower case\n",
    "\"\"\"\n",
    "def changeChars(file_input):\n",
    "    output = 'temp.csv'\n",
    "    print('---START CHANGE CHARS---')\n",
    "    start_time = time.time()\n",
    "\n",
    "    with open(file_input,\"r\") as csvfile:\n",
    "        reader = UnicodeDictReader( csvfile )   \n",
    "        writefile = open(output,'wb') \n",
    "        writer=csv.writer(writefile, delimiter=',')\n",
    "        writer.writerow(['NAMELAST'] + ['NAMEFIRST'])\n",
    "    \n",
    "        for row in reader:\n",
    "            l_name= unicode(row['NAMELAST'])\n",
    "            l_name = unicode.title(l_name).encode('latin-1')\n",
    "        \n",
    "            f_name = unicode(row['NAMEFIRST'])\n",
    "            f_name = unicode.title(f_name).encode('latin-1')\n",
    "            writer.writerow([l_name] + [f_name])\n",
    "        writefile.close()\n",
    "    os.remove(file_input)\n",
    "    os.rename(output,file_input)\n",
    "    print('---FINISH CHANGE CHARS---')\n",
    "    print(\"--- %s seconds ---\\n\" % (time.time() - start_time))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "def getAmount(path,rank,comp):    \n",
    "    print('---START GET NUMBER---')\n",
    "    start_time = time.time()\n",
    "    if(rank==1):\n",
    "        movlist = 'movies/movielist_top.csv'\n",
    "    else:\n",
    "        movlist = 'movies/movielist_bottom.csv'\n",
    "    movielist=[]\n",
    "    movielist = getMoviefiles(path)\n",
    "    \n",
    "    for movie in movielist:\n",
    "        filename = unicode(movie,'latin-1').rsplit('/',1)[1]\n",
    "        filename = unicode(filename).rsplit('.',1)[0]\n",
    "        #print(movie)\n",
    "        \n",
    "        with open (movie,'r')as moviefile:\n",
    "            data_1 = pandas.read_csv(moviefile, sep=',')\n",
    "            result = Count_Row=data_1.shape[0]\n",
    "            #print(result)\n",
    "        moviefile.close()\n",
    "        \n",
    "        with open(movlist,'r') as csvfile:\n",
    "            \"\"\"\n",
    "            for encoding look in https://docs.python.org/3/library/codecs.html#standard-encodings\n",
    "            and check entity aliases\n",
    "            \"\"\"\n",
    "            data_2 = pandas.read_csv(csvfile, sep=',',encoding = 'latin1') \n",
    "        csvfile.close() \n",
    "        \n",
    "        writefile = open(movlist,'wb') \n",
    "        writer=csv.writer(writefile, delimiter=',')    \n",
    "        writer.writerow(['TITLE'] + ['RATE']+ ['WHITEHOUSE']+ ['DBLP'])\n",
    "    \n",
    "        for row in data_2.itertuples():\n",
    "            title=unicode(row[1])\n",
    "            rate=unicode(row[2])\n",
    "            white = unicode(row[3])\n",
    "            dblp = unicode(row[4])\n",
    "            \n",
    "            if(title == filename and comp == 1):\n",
    "                white = unicode(result) \n",
    "            \n",
    "            if(title == filename and comp == 0):\n",
    "                dblp = unicode(result)\n",
    "            \n",
    "            writer.writerow([unicode(title).encode('latin-1')] + [rate] + [white] + [dblp])\n",
    "        writefile.close()\n",
    "    print (\"FINISH\")   \n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "def getMoviefiles(path):    \n",
    "    directorylist = os.listdir(path)\n",
    "    csvList=[]\n",
    "    for i in directorylist:\n",
    "        if \".csv\" in i:\n",
    "            #print (\"selected: %s\"%i)\n",
    "            csvList.append(path+'/'+i)\n",
    "    return csvList\n",
    "\n",
    "\"\"\"\n",
    "This function merges to files by the use of the inner join function.\n",
    "This is usefull to get the total amount of people played in a movie and\n",
    "visit for example the whitehouse.\n",
    "\"\"\"\n",
    "def pandas_mergeFiles(file_input_1,file_input_2,file_output):\n",
    "    #print('---START MERGING---') \n",
    "    start_time = time.time()   \n",
    "    data_1 = pandas.read_csv(file_input_1, sep=',')\n",
    "    data_2 = pandas.read_csv(file_input_2,sep=',')\n",
    "     \n",
    "    result=pandas.merge(data_1,data_2,how='inner')\n",
    "    result.to_csv(file_output,index=False)\n",
    "    #print(\"---FINISH---\")\n",
    "    #print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "def getMergeFiles(file_input,rank):\n",
    "    print('---START MERGING---')\n",
    "    start_time = time.time()\n",
    "    csvList=[]\n",
    "    comp = 0\n",
    "    mydirectory = os.getcwd()\n",
    "    mydirectory = mydirectory.replace(\"\\\\\", \"/\")\n",
    "    if(rank == 1):\n",
    "        mydirectory= mydirectory+'/movies/top'\n",
    "        mergepath = mydirectory+'/merge/' \n",
    "    else:\n",
    "        mydirectory= mydirectory+'/movies/bottom'\n",
    "        mergepath = mydirectory+'/merge/'\n",
    "    print(file_input)\n",
    "    if \"Whitehouse_visits.csv\" == file_input:\n",
    "        comp = 1\n",
    "    \n",
    "    path_exists = os.path.exists(mergepath)\n",
    "    if not (path_exists):\n",
    "        os.makedirs(mergepath)\n",
    "   \n",
    "    csvList=getMoviefiles(mydirectory)\n",
    "    \n",
    "    for csvf in csvList:\n",
    "        mergepath = unicode(csvf,'latin-1').rsplit('/',1)[0]\n",
    "        mergefile = unicode(csvf,'latin-1').rsplit('/',1)[1]\n",
    "        output = mergepath+'/merge/'+mergefile\n",
    "        output = output.replace(\"\\\\\", \"/\")\n",
    "        #print(output)\n",
    "        csvf = csvf.replace(\"\\\\\", \"/\")\n",
    "        #print (csvf)\n",
    "        #print(file_input)\n",
    "        pandas_mergeFiles(file_input,csvf,output)\n",
    "        deleteDuplicates(output)\n",
    "            \n",
    "    getAmount(mydirectory+'/merge',rank,comp)\n",
    "\n",
    "    print(\"---FINISH---\")\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "##################################################################\n",
    "# GET DATA FROM IMDB\n",
    "##################################################################\n",
    "# get access to imdb api\n",
    "try:\n",
    "    imdb_access = imdb.IMDb()\n",
    "    print \"Connection succesful\"\n",
    "except imdb.IMDbError, err:\n",
    "    print err\n",
    "    \n",
    "    \n",
    "topMovies=[]\n",
    "bottomMovies=[]\n",
    "    \n",
    "# class for movie objects\n",
    "class Movie:\n",
    "    name=\"\"\n",
    "    year=0\n",
    "    rating=\"\"\n",
    "    movie_id=\"\"\n",
    "    directors=[]\n",
    "    writers=[]\n",
    "    cast=[]\n",
    "    \n",
    "    def __init__(self, _name, _year, _rating, _id):\n",
    "        self.name=_name\n",
    "        self.year=_year\n",
    "        self.rating=_rating\n",
    "        self.movie_id=_id\n",
    "        \n",
    "\n",
    "# scrape the list of top/bottom100 movies from imdb \n",
    "# ------------------------------------------\n",
    "def scrapeWebpage( _url ):\n",
    "    page=urllib2.urlopen(_url)\n",
    "    soup = BeautifulSoup(page.read(), \"lxml\")\n",
    "\n",
    "    movies = []\n",
    "    table = soup.find('table', attrs={'class':'chart'})\n",
    "    table_body = table.find('tbody')\n",
    "\n",
    "    rows = table_body.findAll('tr')\n",
    "    movie_number = 1\n",
    "    for row in rows:\n",
    "        cols = row.findAll('td')\n",
    "\n",
    "        # Get the title + year from title column\n",
    "        title_column = row.find('td', attrs={'class':'titleColumn'})\n",
    "        title_column_string = title_column.text.strip().encode('latin-1')#latin-1\n",
    "        item_length = len(title_column)\n",
    "        movie_name = title_column_string[5:item_length-12].replace(\"\\n\", \" \").strip()\n",
    "        movie_year = title_column_string[item_length-10:item_length-6].replace(\"\\n\", \" \").strip()\n",
    "\n",
    "        # Get the rating from the rating column\n",
    "        rating_column = row.find('td', attrs={'class':'ratingColumn imdbRating'}).text.strip().encode('latin-1')#latin-1\n",
    "        movie_rating = rating_column.strip()\n",
    "\n",
    "        # Parse the id of the title from title column\n",
    "        title_link = title_column.find_all('a', href=True)\n",
    "        title_link_text = title_link[0]['href']\n",
    "        movie_id = title_link_text[9:16]\n",
    "\n",
    "        # create movie and add to list \n",
    "        movie = Movie(movie_name, movie_year, movie_rating, movie_id)\n",
    "        if int(movie_year) >= 1950:\n",
    "            movies.append(movie)\n",
    "        movie_number = movie_number+1\n",
    "\n",
    "        # Stop after X movies\n",
    "        if (len(movies) == 100):\n",
    "            break\n",
    "            \n",
    "    return movies;\n",
    "\n",
    "\n",
    "def getExtraInformation(movie,rank):\n",
    "    \n",
    "    #print \"\\nMovie\", movie.name, \"(\", movie.year, \") with rating\", movie.rating, \"and ID\", movie.movie_id\n",
    "    \n",
    "    # get the missing information about the movie\n",
    "    found_movie = imdb_access.get_movie(movie.movie_id)\n",
    "    writeMovieList(movie,rank)   \n",
    "    # cast, director, production manager, composer, writer, producer\n",
    "    if ('director' in found_movie.keys()):\n",
    "        count=0\n",
    "        for director in found_movie['director']:\n",
    "            directors = []\n",
    "            name = unicode(director).encode('latin-1')\n",
    "            try:\n",
    "                f_name = name.rsplit(' ',1)[0]\n",
    "                l_name = name.rsplit(' ',1)[1]\n",
    "                directors.append(l_name)\n",
    "                directors.append(f_name)\n",
    "                directors.append('Director')\n",
    "                saveToFiles(movie, directors, rank)\n",
    "                count=count+1\n",
    "            except:\n",
    "                None\n",
    "    #print (\"%d directors added!\"%count)\n",
    "    if ('writer' in found_movie.keys()):\n",
    "        count=0\n",
    "        for writer in found_movie['writer']:\n",
    "            writers = []\n",
    "            name = unicode(writer).encode('latin-1')\n",
    "            try:\n",
    "                f_name = name.rsplit(' ',1)[0]\n",
    "                l_name = name.rsplit(' ',1)[1]\n",
    "                writers.append(l_name)\n",
    "                writers.append(f_name)\n",
    "                writers.append('Writer')\n",
    "                saveToFiles(movie, writers, rank)\n",
    "                count=count+1\n",
    "            except:\n",
    "                None\n",
    "    #print (\"%d writers added!\"%count)\n",
    "    \n",
    "    if ('cast' in found_movie.keys()):\n",
    "        count=0\n",
    "        for actor in found_movie['cast']:\n",
    "            cast = []\n",
    "            name = unicode(actor).encode('latin-1')\n",
    "            try:\n",
    "                f_name = name.rsplit(' ',1)[0]\n",
    "                l_name = name.rsplit(' ',1)[1]\n",
    "                cast.append(l_name)\n",
    "                cast.append(f_name)\n",
    "                cast.append('Actor')\n",
    "                saveToFiles(movie, cast, rank)\n",
    "                count=count+1\n",
    "            except:\n",
    "                None\n",
    "            \n",
    "    #print (\"%d actors added!\"%count)\n",
    "    \n",
    "    return;\n",
    "\"\"\"\n",
    "This function writes all selected movies in the top or bottom list according to their rating.\n",
    "It also includes the number of whitehouse and dblp visits.\n",
    "\"\"\"      \n",
    "def writeMovieList(movie,rank):\n",
    "    \n",
    "    if(rank>0):\n",
    "        path = os.getcwd()\n",
    "        path = path.replace(\"\\\\\", \"/\")\n",
    "        path = path+\"/movies\"\n",
    "        filename = path+\"/movielist_top.csv\"\n",
    "        \n",
    "    else:\n",
    "        path = os.getcwd()        \n",
    "        path = path.replace(\"\\\\\", \"/\")\n",
    "        path = path+\"/movies\"\n",
    "        filename = path+\"/movielist_bottom.csv\"\n",
    "    \n",
    "    path_exists = os.path.exists(path)\n",
    "    if not (path_exists):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    file_exists = os.path.exists(filename)\n",
    "    if not (file_exists): \n",
    "        writefile = open(filename,'wb') \n",
    "        writer=csv.writer(writefile, delimiter=',')       \n",
    "        writer.writerow(['TITLE'] + ['RATE'] + ['WHITEHOUSE']+ ['DBLP'])\n",
    "        writefile.close()\n",
    "    \n",
    "    with open(filename, \"ab\") as writefile:\n",
    "        writer = csv.writer(writefile,delimiter=',')\n",
    "        writer.writerow([movie.name] + [movie.rating])\n",
    "    writefile.close()\n",
    "    \n",
    "def saveToFiles( movie,persons, pos ): # pos = position (0 = bottom, 1 = top)\n",
    "    # save the movies by files (<movie.name>.<year>.<rating-rating>.[directors|writer|cast]) for each person-Array\n",
    "    \n",
    "    # build filename\n",
    "    if (pos == 1):\n",
    "        path = os.getcwd()\n",
    "        path = path.replace(\"\\\\\", \"/\")\n",
    "        path = path+\"/movies/top/\"\n",
    "        #filename = os.path.dirname(os.path.abspath(__file__))+\"/movies/top/\"\n",
    "    else:\n",
    "        path = os.getcwd()\n",
    "        path = path.replace(\"\\\\\", \"/\")\n",
    "        path = path+\"/movies/bottom/\"\n",
    "        #filename = os.path.dirname(os.path.abspath(__file__))+\"/movies/bottom/\"\n",
    "    \n",
    "    path_exists = os.path.exists(path)\n",
    "    if not (path_exists):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    filename = path+movie.name+\".csv\"\n",
    "    file_exists = os.path.exists(filename)\n",
    "    #write header\n",
    "    if not(file_exists):\n",
    "        writefile = open(filename,'wb') \n",
    "        writer=csv.writer(writefile, delimiter=',')       \n",
    "        writer.writerow(['NAMELAST'] + ['NAMEFIRST'] + ['JOB'])\n",
    "        writefile.close()\n",
    "        \n",
    "    #store data\n",
    "    with open(filename, \"ab\") as writefile:\n",
    "        writer = csv.writer(writefile,delimiter=',')\n",
    "        writer.writerow([persons[0]] + [persons[1]] + [persons[2]])\n",
    "    writefile.close()\n",
    "    \n",
    "    return;\n",
    " \n",
    "def getIMDB():\n",
    "    \n",
    "    print('---START GET MOVIES---')\n",
    "    start_time = time.time()\n",
    "    topMovies = scrapeWebpage( \"http://www.imdb.com/chart/top\" )\n",
    "    bottomMovies = scrapeWebpage( \"http://www.imdb.com/chart/bottom\" )\n",
    "    \n",
    "    print \"Top Movies:\"\n",
    "    for movie in topMovies:\n",
    "        getExtraInformation(movie,1)\n",
    "    print('Got %d movies' %len(topMovies))\n",
    "        \n",
    "    print \"Bottom Movies:\"\n",
    "    for movie in bottomMovies:\n",
    "        getExtraInformation(movie,0)\n",
    "    print('Got %d movies' %len(bottomMovies))\n",
    "    \n",
    "    print('---FINISH GET MOVIES---')\n",
    "    print(\"--- %s seconds ---\\n\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "##################################################################\n",
    "# GET DATA FROM DBLP\n",
    "##################################################################\n",
    "\"\"\"\n",
    "This Function is able to read the given dblp.xml and writes the given names\n",
    "into a new csv file, seperated into namelast, namefirst.\n",
    "\"\"\"\n",
    "def getDBLP(f_in,f_out):\n",
    "    \n",
    "    print('---START READING AUTHORS---')\n",
    "   \n",
    "    writefile = open(f_out, 'wb')\n",
    "    writefile.write('NAMELAST,NAMEFIRST\\n')\n",
    "    writefile.close()\n",
    "\n",
    "    context = lxmletree.iterparse(f_in, resolve_entities=True, load_dtd=True, tag='author')\n",
    "    start_time = time.time()\n",
    "    # Set start value for counting elements\n",
    "    \n",
    "    list = []\n",
    "    for event, elem in context:\n",
    "        try:\n",
    "            author = elem.text.encode('latin-1')\n",
    "            author = re.sub('[\\d]','',author)\n",
    "            author = author.rstrip()\n",
    "            \n",
    "        except:\n",
    "            author=''\n",
    "        if not(author==''):\n",
    "            try:\n",
    "                namefirst = author.rsplit(' ',1)[0]\n",
    "            except:\n",
    "                namefirst=''\n",
    "            try:\n",
    "                namelast = author.rsplit(' ',1)[1]\n",
    "            except:\n",
    "                namelast=''\n",
    "        list.append(namelast+\",\"+namefirst)\n",
    "        \n",
    "        if (len(list)>50000):    \n",
    "            writefile = open(f_out, 'ab')  # a = add b = byte\n",
    "            \n",
    "            for i in list:   \n",
    "                #print (i)\n",
    "                writefile.write('%s\\n' % i)\n",
    "            writefile.close()\n",
    "            list = []\n",
    "        \n",
    "        # It's safe to call clear() here because no descendants will be accessed\n",
    "        elem.clear()\n",
    "        # Also eliminate now-empty references from the root node to <Title> \n",
    "        for ancestor in elem.xpath('ancestor-or-self::*'):\n",
    "            while ancestor.getprevious() is not None:\n",
    "                del ancestor.getparent()[0]\n",
    "              \n",
    "    print(\"--- FINISH ---\")   \n",
    "    print(\"--- %s seconds ---\\n\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "##################################################################\n",
    "# GET DATA FROM WHITEHOUSE\n",
    "##################################################################\n",
    "\"\"\"\n",
    "This Function iterates through the given whitehouse file and reads and \n",
    "writes all given names in this file. The names will be seperated into \n",
    "namelast, namefirst.\n",
    "\"\"\"\n",
    "def getWhitehouseValues(file_input,file_output):  \n",
    "    print('---START SHRINKING WHITEHOUSE FILE---')\n",
    "    start_time = time.time()\n",
    "    data_1 = pandas.read_csv(file_input, sep=',', iterator=True, chunksize=10000, engine='python')\n",
    "    for row in data_1:\n",
    "        result=row[['NAMELAST','NAMEFIRST']]\n",
    "        result.to_csv(file_output,index=False,mode='ab')\n",
    "    print (\"---FINISH---\")   \n",
    "    print(\"--- %s seconds ---\\n\" % (time.time() - start_time))\n",
    "\n",
    "##################################################################\n",
    "# GET PLOTS\n",
    "##################################################################    \n",
    "\"\"\"\n",
    "This Function creates all relevant plots from the created datasource.\n",
    "\"\"\"\n",
    "def getPlot():\n",
    "    print('---PLOTTING RESULTS---')\n",
    "    df1 = pandas.read_csv('movies/movielist_bottom.csv', sep=',')    \n",
    "    df2 = pandas.read_csv('movies/movielist_top.csv', sep=',')\n",
    "   \n",
    "    #Scatterplots \n",
    "    ##############\n",
    "    #Whitehouse and Movies\n",
    "    ax = df1.plot.scatter(x='RATE', y='WHITEHOUSE', color='Red',s=20, label='Worst Movies',\n",
    "                          figsize=(15, 10),title='Dependency Whitehouse and movie rating');\n",
    "    df2.plot.scatter(x='RATE',y='WHITEHOUSE', color='Green',s=20, label='Best Movies',grid=True, ax=ax);\n",
    "    \n",
    "    ##############\n",
    "    #DBLP and Movies\n",
    "    ax = df1.plot.scatter(x='RATE', y='DBLP', color='Red',s=20, label='Worst Movies',\n",
    "                          figsize=(15, 10),title='Dependency DBLP and movie rating');\n",
    "    df2.plot.scatter(x='RATE',y='DBLP', color='Green',s=20, label='Best Movies',grid=True, ax=ax);\n",
    "        \n",
    "    #Average amount\n",
    "    av_bottom_white = (df1['WHITEHOUSE'].sum()/df1['WHITEHOUSE'].count())\n",
    "    av_top_white = (df2['WHITEHOUSE'].sum()/df2['WHITEHOUSE'].count()) \n",
    "    \n",
    "    av = pandas.DataFrame({'TOP-MOVIES':[av_top_white], 'BOTTOM-MOVIES':[av_bottom_white]})\n",
    "    av.plot(kind='bar', title='Compare average visits in whitehouse',grid=True,figsize=(15, 10))\n",
    "    \n",
    "    av_bottom_dblp = (df1['DBLP'].sum()/df1['DBLP'].count())\n",
    "    av_top_dblp = (df2['DBLP'].sum()/df2['DBLP'].count()) \n",
    "    \n",
    "    av = pandas.DataFrame({'TOP-MOVIES':[av_top_dblp], 'BOTTOM-MOVIES':[av_bottom_dblp]})\n",
    "    av.plot(kind='bar', title='Compare average amount of authors paper in dblp',grid=True,figsize=(15, 10))\n",
    "        \n",
    "    df1 = pandas.read_csv('dblp_authors.csv', sep=',')    \n",
    "    df2 = pandas.read_csv('Whitehouse_visits.csv', sep=',')\n",
    "    df3 = pandas.read_csv('dblp_whitehouse.csv', sep=',')    \n",
    "    \n",
    "    ##############\n",
    "    #Whitehouse and DBLP\n",
    "    white = (df1['NAMELAST'].count())\n",
    "    dblp = (df2['NAMELAST'].count())\n",
    "    av_wd = (df3['NAMELAST'].count())    \n",
    "    av = pandas.DataFrame({'Whitehouse':[white], 'DBLP':[dblp], 'mixed':[av_wd]})\n",
    "    av.plot(kind='barh', title='Compare visits in whitehouse from authors in dblp',figsize=(15, 10),grid=True, use_index=True,legend=True)\n",
    "   \n",
    "    #Creates the plots\n",
    "    plt.show()\n",
    "\n",
    "##################################################################\n",
    "# RUN AREA        \n",
    "##################################################################\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    getWhitehouseValues('White_House_Visitor_Records_Requests.csv','Whitehouse_visits.csv')\n",
    "    sortAndCleanCSV('Whitehouse_visits.csv')\n",
    "    deleteDuplicates('Whitehouse_visits.csv')\n",
    "    changeChars('Whitehouse_visits.csv')\n",
    "    sortAndCleanCSV('Whitehouse_visits.csv')\n",
    "    deleteDuplicates('Whitehouse_visits.csv')\n",
    "    getDBLP(\"dblp.xml\",\"dblp_authors.csv\")\n",
    "    sortAndCleanCSV('dblp_authors.csv')\n",
    "    deleteDuplicates('dblp_authors.csv')\n",
    "    getIMDB()\n",
    "    start_time = time.time()\n",
    "    print('---START OVERALL MERGING---')\n",
    "    getMergeFiles('Whitehouse_visits.csv',1)\n",
    "    getMergeFiles('Whitehouse_visits.csv',0)\n",
    "    getMergeFiles('dblp_authors.csv',1)\n",
    "    getMergeFiles('dblp_authors.csv',0)\n",
    "    pandas_mergeFiles('dblp_authors.csv','Whitehouse_visits.csv','dblp_whitehouse.csv')\n",
    "    print(\"---FINISHED OVERALL MERGING---\")\n",
    "    print(\"--- %s seconds ---\\n\" % (time.time() - start_time))\n",
    "    getPlot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
